{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_fake_upec_task_torch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "670e475eadbc4a1fb536f1e040148d33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31b24017c1e34cf085eec0d0c86e2a17",
              "IPY_MODEL_0319700f94364e0a837775316040310a",
              "IPY_MODEL_822d38a0e8b84d11812b665898a4ed43"
            ],
            "layout": "IPY_MODEL_62551c89fc7f476d8be313999c392e54"
          }
        },
        "31b24017c1e34cf085eec0d0c86e2a17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39053f961eaf48ae93ef2c469cf31849",
            "placeholder": "​",
            "style": "IPY_MODEL_3047be5e4346487a8dec7f4149d92489",
            "value": "100%"
          }
        },
        "0319700f94364e0a837775316040310a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50cd0a5df8264d37b3a168bef892c990",
            "max": 102502400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_786bb93b22ee4f3ab29f1eb7d8196e15",
            "value": 102502400
          }
        },
        "822d38a0e8b84d11812b665898a4ed43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35707d052d2e452486de1612674eab55",
            "placeholder": "​",
            "style": "IPY_MODEL_bbcb0ff87155494b8c7af2408f0a9a6d",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 220MB/s]"
          }
        },
        "62551c89fc7f476d8be313999c392e54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39053f961eaf48ae93ef2c469cf31849": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3047be5e4346487a8dec7f4149d92489": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50cd0a5df8264d37b3a168bef892c990": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "786bb93b22ee4f3ab29f1eb7d8196e15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35707d052d2e452486de1612674eab55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbcb0ff87155494b8c7af2408f0a9a6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_YN9pZi1bRr",
        "outputId": "c96ff496-3b64-4c32-b42c-dd5e511dea43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pretrainedmodels split-folders tqdm"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pretrainedmodels\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▋                          | 10 kB 35.7 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20 kB 42.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 30 kB 38.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 40 kB 29.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 51 kB 33.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 58 kB 7.2 MB/s \n",
            "\u001b[?25hCollecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels) (0.12.0+cu113)\n",
            "Collecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from munch->pretrainedmodels) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pretrainedmodels) (4.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->pretrainedmodels) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->pretrainedmodels) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->pretrainedmodels) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pretrainedmodels) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pretrainedmodels) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pretrainedmodels) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pretrainedmodels) (1.24.3)\n",
            "Building wheels for collected packages: pretrainedmodels\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60965 sha256=b84ae897f307d17d65683856d04d0bad1a75e028c8de69db9bf6de1987ee2da6\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/27/e8/9543d42de2740d3544db96aefef63bda3f2c1761b3334f4873\n",
            "Successfully built pretrainedmodels\n",
            "Installing collected packages: munch, split-folders, pretrainedmodels\n",
            "Successfully installed munch-2.5.0 pretrainedmodels-0.7.4 split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNIK9ZzHv4p-",
        "outputId": "a22b205d-dc4b-4ec2-e85f-8b6035558327"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0-VPpIJ8Rzk"
      },
      "source": [
        "!unzip -q /content/drive/My\\ Drive/data.zip"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AZ59En18PYE"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import splitfolders\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "from copy import deepcopy\n",
        "import pretrainedmodels\n",
        "import pretrainedmodels.utils as utils\n",
        "from shutil import copyfile,copy\n",
        "import glob\n",
        "#os.environ['TORCH_HOME'] = '.'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZznRBkgKrV8",
        "outputId": "da8b6c6a-a52d-4005-e89e-45abc362d98f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Available model : \\n \",pretrainedmodels.model_names)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available model : \n",
            "  ['fbresnet152', 'bninception', 'resnext101_32x4d', 'resnext101_64x4d', 'inceptionv4', 'inceptionresnetv2', 'alexnet', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'inceptionv3', 'squeezenet1_0', 'squeezenet1_1', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19', 'nasnetamobile', 'nasnetalarge', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn131', 'dpn107', 'xception', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'cafferesnet101', 'pnasnet5large', 'polynet']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We are using resnet50 first"
      ],
      "metadata": {
        "id": "h7e6l1RoAePZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkKmcOljCOsQ"
      },
      "source": [
        "DATA_SOURCE = \"data/train\"\n",
        "DATA_PATH = \"dataset\"\n",
        "MODEL_NAME = \"resnet50\"\n",
        "VAL_RATIO = 0.1\n",
        "SEED = 1337\n",
        "EPOCHS = 15\n",
        "PATIENCE = 5\n",
        "GAMMA = 0.1\n",
        "LEARNING_RATE = 0.001\n",
        "MOMENTUM = 0.1\n",
        "STEP_SIZE = 7\n",
        "N_EPOCHS = 50\n",
        "TRAIN_LOADER_BATCH_SIZE = 32\n",
        "TEST_LOADER_BATCH_SIZE = 20 \n",
        "N_WORKER = 1\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # use gpu if available"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdkzLVVoLUdU"
      },
      "source": [
        "def prepare_folds(path_in,path_out,val_ratio=0.2):\n",
        "  splitfolders.ratio(path_in, output=path_out, seed=SEED, ratio=(1-(val_ratio*2),val_ratio,val_ratio), group_prefix=None)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02H_lo_wAONR"
      },
      "source": [
        "def get_loaders(data_dir,transform,bs=32,t_bs=20,n_worker=1):\n",
        "\n",
        "  image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),transform) for x in ['train', 'val']}\n",
        "\n",
        "  dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=bs, shuffle=True, num_workers=n_worker)for x in ['train', 'val']}\n",
        "\n",
        "  image_tests = {\"test\": datasets.ImageFolder(os.path.join(data_dir, \"test\"),transform)}\n",
        "\n",
        "  dataload_test = {\"test\": torch.utils.data.DataLoader(image_tests[\"test\"], batch_size=t_bs,shuffle=False, num_workers=n_worker)}\n",
        "\n",
        "  dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "\n",
        "  class_names = image_datasets['train'].classes\n",
        "\n",
        "  return dataloaders,dataload_test,dataset_sizes,class_names"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca4AK_wlJ4NX"
      },
      "source": [
        "def imshow(inp, model, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    inp = model.std * inp + model.mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKN4NkB1J0_q"
      },
      "source": [
        "class EarlyStopping(object):\n",
        "    def __init__(self, mode='min', min_delta=0, patience=10, percentage=False):\n",
        "        self.mode = mode\n",
        "        self.min_delta = min_delta\n",
        "        self.patience = patience\n",
        "        self.best = None\n",
        "        self.num_bad_epochs = 0\n",
        "        self.is_better = None\n",
        "        self._init_is_better(mode, min_delta, percentage)\n",
        "\n",
        "        if patience == 0:\n",
        "            self.is_better = lambda a, b: True\n",
        "            self.step = lambda a: False\n",
        "\n",
        "    def step(self, metrics):\n",
        "        if self.best is None:\n",
        "            self.best = metrics\n",
        "            return False\n",
        "\n",
        "        if np.isnan(metrics):\n",
        "            return True\n",
        "\n",
        "        if self.is_better(metrics, self.best):\n",
        "            self.num_bad_epochs = 0\n",
        "            self.best = metrics\n",
        "            print('improvement!')\n",
        "        else:\n",
        "            self.num_bad_epochs += 1\n",
        "            print(f'no improvement, bad_epochs counter: {self.num_bad_epochs}')\n",
        "\n",
        "        if self.num_bad_epochs >= self.patience:\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def _init_is_better(self, mode, min_delta, percentage):\n",
        "        if mode not in {'min', 'max'}:\n",
        "            raise ValueError('mode ' + mode + ' is unknown!')\n",
        "        if not percentage:\n",
        "            if mode == 'min':\n",
        "                self.is_better = lambda a, best: a < best - min_delta\n",
        "            if mode == 'max':\n",
        "                self.is_better = lambda a, best: a > best + min_delta\n",
        "        else:\n",
        "            if mode == 'min':\n",
        "                self.is_better = lambda a, best: a < best - (\n",
        "                            best * min_delta / 100)\n",
        "            if mode == 'max':\n",
        "                self.is_better = lambda a, best: a > best + (\n",
        "                            best * min_delta / 100)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D54TE0RJ95C"
      },
      "source": [
        "def train_model(model,dataloaders,dataset_sizes, criterion, optimizer, scheduler, num_epochs=25, patience=5):\n",
        "    \n",
        "    es = EarlyStopping(patience=patience)\n",
        "    terminate_training = False\n",
        "    \n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = deepcopy(model.state_dict())\n",
        "                \n",
        "            if phase == 'val' and es.step(epoch_loss):\n",
        "                terminate_training = True\n",
        "                print('early stop criterion is met, we can stop now')\n",
        "                break\n",
        "    \n",
        "        print()\n",
        "        if terminate_training:\n",
        "            break\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD5wBZFZKLFh"
      },
      "source": [
        "#source kaggle\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NusEKpEKS8j"
      },
      "source": [
        "def visualize_model_test(model, num_images=20):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataload_test['test']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            print(preds)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUXtlSrRKgGQ"
      },
      "source": [
        "def __train__(model_name='xception'):\n",
        "  model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
        "  model.eval()\n",
        "  transform_img = utils.TransformImage(model)\n",
        "  dataloaders, dataload_test, dataset_sizes, class_names = get_loaders(\n",
        "      DATA_PATH,transform_img,bs=TRAIN_LOADER_BATCH_SIZE,t_bs=TEST_LOADER_BATCH_SIZE,n_worker=N_WORKER)\n",
        "  num_ftrs = model.last_linear.in_features\n",
        "  model.last_linear = nn.Linear(num_ftrs, len(class_names))\n",
        "  model = model.to(device)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  # Observe that all parameters are being optimized\n",
        "  optimizer_ft = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
        "  # Decay LR by a factor of GAMMA every STEP_SIZE epochs\n",
        "  exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "  model = train_model(model,dataloaders,dataset_sizes, criterion, optimizer_ft, exp_lr_scheduler,num_epochs=N_EPOCHS)\n",
        "  return model"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm -rf dataset; rm -rf data"
      ],
      "metadata": {
        "id": "-6K4OYxpzci-"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwHQtpsn6ibl",
        "outputId": "3dd9b5d9-fcd8-4899-9051-51f02192ccec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "prepare_folds(DATA_SOURCE,DATA_PATH,VAL_RATIO)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 847 files [00:00, 7594.77 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDl5IrlQDVnj",
        "outputId": "fa79b4c1-6868-41cc-d753-55940f5940d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "670e475eadbc4a1fb536f1e040148d33",
            "31b24017c1e34cf085eec0d0c86e2a17",
            "0319700f94364e0a837775316040310a",
            "822d38a0e8b84d11812b665898a4ed43",
            "62551c89fc7f476d8be313999c392e54",
            "39053f961eaf48ae93ef2c469cf31849",
            "3047be5e4346487a8dec7f4149d92489",
            "50cd0a5df8264d37b3a168bef892c990",
            "786bb93b22ee4f3ab29f1eb7d8196e15",
            "35707d052d2e452486de1612674eab55",
            "bbcb0ff87155494b8c7af2408f0a9a6d"
          ]
        }
      },
      "source": [
        "model = __train__(MODEL_NAME)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "670e475eadbc4a1fb536f1e040148d33"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.6921 Acc: 0.5769\n",
            "val Loss: 0.6859 Acc: 0.5476\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.6530 Acc: 0.6228\n",
            "val Loss: 0.6643 Acc: 0.5833\n",
            "improvement!\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.6248 Acc: 0.6746\n",
            "val Loss: 0.6484 Acc: 0.5952\n",
            "improvement!\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.6036 Acc: 0.6834\n",
            "val Loss: 0.6370 Acc: 0.6190\n",
            "improvement!\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.5677 Acc: 0.7663\n",
            "val Loss: 0.6342 Acc: 0.5952\n",
            "improvement!\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.5420 Acc: 0.7633\n",
            "val Loss: 0.6216 Acc: 0.6429\n",
            "improvement!\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.5220 Acc: 0.7751\n",
            "val Loss: 0.6124 Acc: 0.6548\n",
            "improvement!\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.5145 Acc: 0.8107\n",
            "val Loss: 0.6133 Acc: 0.6667\n",
            "no improvement, bad_epochs counter: 1\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.5002 Acc: 0.8299\n",
            "val Loss: 0.6058 Acc: 0.6429\n",
            "improvement!\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.4961 Acc: 0.8299\n",
            "val Loss: 0.6074 Acc: 0.6190\n",
            "no improvement, bad_epochs counter: 1\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.4953 Acc: 0.8314\n",
            "val Loss: 0.6065 Acc: 0.6310\n",
            "no improvement, bad_epochs counter: 2\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.4848 Acc: 0.8328\n",
            "val Loss: 0.6049 Acc: 0.6190\n",
            "improvement!\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.4879 Acc: 0.8314\n",
            "val Loss: 0.6077 Acc: 0.6190\n",
            "no improvement, bad_epochs counter: 1\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.4878 Acc: 0.8195\n",
            "val Loss: 0.6037 Acc: 0.6429\n",
            "improvement!\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.4846 Acc: 0.8151\n",
            "val Loss: 0.6035 Acc: 0.6548\n",
            "improvement!\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.4837 Acc: 0.8254\n",
            "val Loss: 0.6051 Acc: 0.6429\n",
            "no improvement, bad_epochs counter: 1\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.4789 Acc: 0.8358\n",
            "val Loss: 0.6042 Acc: 0.6429\n",
            "no improvement, bad_epochs counter: 2\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.4852 Acc: 0.8328\n",
            "val Loss: 0.6056 Acc: 0.6429\n",
            "no improvement, bad_epochs counter: 3\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.4814 Acc: 0.8358\n",
            "val Loss: 0.6061 Acc: 0.6548\n",
            "no improvement, bad_epochs counter: 4\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.4809 Acc: 0.8284\n",
            "val Loss: 0.6032 Acc: 0.6310\n",
            "improvement!\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.4824 Acc: 0.8269\n",
            "val Loss: 0.6046 Acc: 0.6429\n",
            "no improvement, bad_epochs counter: 1\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.4866 Acc: 0.8121\n",
            "val Loss: 0.6054 Acc: 0.6429\n",
            "no improvement, bad_epochs counter: 2\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.4853 Acc: 0.8195\n",
            "val Loss: 0.6046 Acc: 0.6190\n",
            "no improvement, bad_epochs counter: 3\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.4806 Acc: 0.8314\n",
            "val Loss: 0.6051 Acc: 0.6310\n",
            "no improvement, bad_epochs counter: 4\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.4814 Acc: 0.8195\n",
            "val Loss: 0.6044 Acc: 0.6190\n",
            "no improvement, bad_epochs counter: 5\n",
            "early stop criterion is met, we can stop now\n",
            "\n",
            "Training complete in 3m 28s\n",
            "Best val Acc: 0.666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VksJgEoG9sEC",
        "outputId": "524f516b-9e8a-4ffb-cc3b-6b65f64987dc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): None\n",
            "  (last_linear): Linear(in_features=2048, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMzLOjIS72Mf"
      },
      "source": [
        "torch.save(model.state_dict(), 'saved_model_'+MODEL_NAME+'_.pth')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r10WwKD8I3m"
      },
      "source": [
        "transform_img = utils.TransformImage(model)\n",
        "dataloaders, dataload_test, dataset_sizes, class_names = get_loaders(\n",
        "      DATA_PATH,transform_img,bs=TRAIN_LOADER_BATCH_SIZE,t_bs=TEST_LOADER_BATCH_SIZE,n_worker=N_WORKER)"
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}